{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1416fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "\n",
    "#set seed\n",
    "SEED = 1339\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "#set up GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#load csvs\n",
    "csv_paths = [f\"Unit2_RNN_rev1_dataset_{i}.csv\" for i in range(1, 5)] + \\\n",
    "            [f\"Unit4_RNN_rev1_dataset_{i}.csv\" for i in range(1, 4)]\n",
    "        \n",
    "\n",
    "datasets_raw = []  #list of (X_raw, Y_raw) tuples\n",
    "\n",
    "for path in csv_paths:\n",
    "    df = pd.read_csv(path)\n",
    "    X_raw = df[[f\"X{i}\" for i in range(1, 13)]].values  #shape: [num_samples, 12]\n",
    "    Y_raw = df[[\"Y1\", \"Y2\"]].values           #shape: [num_samples, 2]\n",
    "    datasets_raw.append((X_raw, Y_raw))\n",
    "\n",
    "#splitting data (70/20/10)\n",
    "datasets_split = []  #list of (X_train, X_val, X_test, Y_train, Y_val, Y_test)\n",
    "\n",
    "for X_raw, Y_raw in datasets_raw:\n",
    "    n = len(X_raw)\n",
    "    train_end = int(n * 0.7)\n",
    "    val_end   = int(n * 0.9)\n",
    "\n",
    "    X_train = X_raw[:train_end]\n",
    "    X_val   = X_raw[train_end:val_end]\n",
    "    X_test  = X_raw[val_end:]\n",
    "\n",
    "    Y_train = Y_raw[:train_end]\n",
    "    Y_val   = Y_raw[train_end:val_end]\n",
    "    Y_test  = Y_raw[val_end:]\n",
    "\n",
    "    datasets_split.append((X_train, X_val, X_test, Y_train, Y_val, Y_test))\n",
    "\n",
    "#global scalers on all the train data together \n",
    "X_train_all = np.concatenate([X_train for (X_train, _, _, _, _, _) in datasets_split], axis=0)\n",
    "Y_train_all = np.concatenate([Y_train for (_, _, _, Y_train, _, _) in datasets_split], axis=0)\n",
    "\n",
    "X_scaler_global = MinMaxScaler()\n",
    "Y_scaler_global = RobustScaler()\n",
    "\n",
    "X_scaler_global.fit(X_train_all)\n",
    "Y_scaler_global.fit(Y_train_all)\n",
    "\n",
    "#scale all datasets with this scaler\n",
    "datasets_scaled = []\n",
    "for X_train, X_val, X_test, Y_train, Y_val, Y_test in datasets_split:\n",
    "    X_train_scaled = X_scaler_global.transform(X_train)\n",
    "    X_val_scaled   = X_scaler_global.transform(X_val)\n",
    "    X_test_scaled  = X_scaler_global.transform(X_test)\n",
    "\n",
    "    Y_train_scaled = Y_scaler_global.transform(Y_train)\n",
    "    Y_val_scaled   = Y_scaler_global.transform(Y_val)\n",
    "    Y_test_scaled  = Y_scaler_global.transform(Y_test)\n",
    "\n",
    "    datasets_scaled.append((X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled))\n",
    "\n",
    "# ==== TORCH TENSORS ====\n",
    "datasets_tensors = []  # list of (X_train_tensor, X_val_tensor, X_test_tensor, Y_train_tensor, Y_val_tensor, Y_test_tensor)\n",
    "for (X_train_scaled, X_val_scaled, X_test_scaled, Y_train_scaled, Y_val_scaled, Y_test_scaled) in datasets_scaled:\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)  \n",
    "    X_val_tensor   = torch.tensor(X_val_scaled,   dtype=torch.float32)\n",
    "    X_test_tensor  = torch.tensor(X_test_scaled,  dtype=torch.float32)\n",
    "\n",
    "    Y_train_tensor = torch.tensor(Y_train_scaled, dtype=torch.float32)\n",
    "    Y_val_tensor   = torch.tensor(Y_val_scaled,   dtype=torch.float32)\n",
    "    Y_test_tensor  = torch.tensor(Y_test_scaled,  dtype=torch.float32)\n",
    "\n",
    "    datasets_tensors.append((X_train_tensor, X_val_tensor, X_test_tensor,Y_train_tensor, Y_val_tensor, Y_test_tensor))\n",
    "\n",
    "#sequencing parameters \n",
    "input_seq_len  = 32\n",
    "output_seq_len = 8\n",
    "stride_train   = 1 #most training instances possible\n",
    "stride_eval    = output_seq_len  #no overlapping targets for val/test\n",
    "\n",
    "def create_sequences_ar(\n",
    "    X: torch.Tensor, Y: torch.Tensor,\n",
    "    input_length: int, output_length: int, stride: int = 1\n",
    "):\n",
    "    #extract number of time steps\n",
    "    total_timesteps = X.size(0)\n",
    "    #length of input sequence + output sequence\n",
    "    total_length = input_length + output_length\n",
    "    # Number of windows given stride // floors the quotient\n",
    "    N = (total_timesteps - total_length) // stride + 1\n",
    "\n",
    "    #create windows and reorder for Batch = First\n",
    "    X_past = (\n",
    "        X.unfold(0, input_length, stride)[:N]\n",
    "         .permute(0, 2, 1)               \n",
    "         .contiguous()\n",
    "    )\n",
    "    Y_future = (\n",
    "        Y[input_length:]\n",
    "         .unfold(0, output_length, stride)[:N]\n",
    "         .permute(0, 2, 1)             \n",
    "         .contiguous()\n",
    "    )\n",
    "    return X_past, Y_future\n",
    "\n",
    "#build per-dataset windows\n",
    "# Each entry: (Xp_tr, Xp_val, Xp_te, Y_tr, Y_val, Y_te)\n",
    "datasets_seq2seq = []\n",
    "\n",
    "for x_train, x_val, x_test, y_train, y_val, y_test in datasets_tensors:\n",
    "    #train sequences\n",
    "    x_train_seq, y_train_seq = create_sequences_ar(x_train, y_train, input_seq_len, output_seq_len, stride=stride_train)\n",
    "    #val sequencies\n",
    "    x_val_seq, y_val_seq = create_sequences_ar(x_val, y_val, input_seq_len, output_seq_len, stride=stride_eval)\n",
    "    #test sequences\n",
    "    x_test_seq, y_test_seq = create_sequences_ar(x_test, y_test, input_seq_len, output_seq_len, stride=stride_eval)\n",
    "\n",
    "    datasets_seq2seq.append((x_train_seq, x_val_seq, x_test_seq, y_train_seq, y_val_seq, y_test_seq))\n",
    "\n",
    "\n",
    "class EncoderDecoderAR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,    \n",
    "        hidden_size: int,\n",
    "        output_size: int,   \n",
    "        input_seq_len: int,\n",
    "        output_seq_len: int,\n",
    "        num_layers: int = 1,\n",
    "        dropout_p: float = 0.2,\n",
    "        tf_ratio: float = 0.75\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_seq_len  = input_seq_len\n",
    "        self.output_seq_len = output_seq_len\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.output_size    = output_size\n",
    "        self.num_layers     = num_layers\n",
    "        self.tf_ratio       = tf_ratio\n",
    "\n",
    "        self.log_tf_usage = False\n",
    "        self._tf_total_steps = 0\n",
    "        self._tf_tf_steps    = 0\n",
    "\n",
    "        # Encoder (stacked; dropout only active if num_layers > 1)\n",
    "        self.encoder = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=(dropout_p if num_layers > 1 else 0.0)\n",
    "        )\n",
    "\n",
    "        # Decoder consumes only prev_y (size = O)\n",
    "        self.decoder_in_size = output_size\n",
    "        self.decoder = nn.RNN(\n",
    "            input_size=self.decoder_in_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Output projection\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def reset_tf_counters(self):\n",
    "        self._tf_total_steps = 0\n",
    "        self._tf_tf_steps    = 0\n",
    "\n",
    "    \n",
    "# FORWARD FOR RNN/GRU\n",
    "def forward(self, past_inputs: torch.Tensor, target_seq: torch.Tensor = None):\n",
    "    batch_size = past_inputs.size(0)\n",
    "    device = past_inputs.device\n",
    "\n",
    "    #encode past sequence\n",
    "    _, encoder_hidden = self.encoder(past_inputs)     #[num_layers, batch, hidden]\n",
    "    hidden_state = encoder_hidden[-1:].contiguous()     #seed decoder with top layer -> [1, batch, hidden]\n",
    "\n",
    "    #initialize previous output as zeros\n",
    "    previous_output = torch.zeros(batch_size, 1, self.output_size, device=device)\n",
    "\n",
    "    predictions = []\n",
    "    for t in range(self.output_seq_len):      #iterate over each output time step\n",
    "        decoder_input = previous_output     #[batch, 1, output]\n",
    "        decoder_output, hidden_state = self.decoder(decoder_input, hidden_state)\n",
    "        predicted_output = self.fc_out(decoder_output)    # [batch, 1, output]\n",
    "        predictions.append(predicted_output)\n",
    "\n",
    "        #teacher forcing decision\n",
    "        if self.training and target_seq is not None and self.tf_ratio > 0.0:\n",
    "            use_teacher_forcing = torch.rand(1, device=device).item() < self.tf_ratio\n",
    "            if self.log_tf_usage:\n",
    "                self._tf_total_steps += 1\n",
    "                if use_teacher_forcing:\n",
    "                    self._tf_tf_steps += 1\n",
    "            previous_output = target_seq[:, t:t+1, :] if use_teacher_forcing else predicted_output.detach()\n",
    "        else:\n",
    "            previous_output = predicted_output.detach()     #detach autoregressive feedback\n",
    "\n",
    "    return torch.cat(predictions, dim=1)      #[batch, output_seq_len, output_size]\n",
    "\n",
    "\n",
    "#LSTM FORWARD\n",
    "\"\"\"\n",
    "def forward(self, past_inputs: torch.Tensor, target_seq: torch.Tensor = None):\n",
    "    batch_size = past_inputs.size(0)\n",
    "    device = past_inputs.device\n",
    "\n",
    "    #encode with lstm -> (h_n, c_n): [num_layers, batch, hidden]\n",
    "    _, (h_n, c_n) = self.encoder(past_inputs)\n",
    "    hidden_state = h_n[-1:].contiguous()      # [1, batch, hidden]\n",
    "    cell_state = c_n[-1:].contiguous()        # [1, batch, hidden]\n",
    "\n",
    "    #initialize previous output as zeros\n",
    "    previous_output = torch.zeros(batch_size, 1, self.output_size, device=device)\n",
    "\n",
    "    predictions = []\n",
    "    for t in range(self.output_seq_len):\n",
    "        decoder_input = previous_output       #[batch, 1, output]\n",
    "        decoder_output, (hidden_state, cell_state) = self.decoder(decoder_input, (hidden_state, cell_state))\n",
    "        predicted_output = self.fc_out(decoder_output)     #[batch, 1, output]\n",
    "        predictions.append(predicted_output)\n",
    "\n",
    "        #teacher forcing logic\n",
    "        if self.training and target_seq is not None and self.tf_ratio > 0.0:\n",
    "            use_teacher_forcing = torch.rand(1, device=device).item() < self.tf_ratio\n",
    "            if self.log_tf_usage:\n",
    "                self._tf_total_steps += 1\n",
    "                if use_teacher_forcing:\n",
    "                    self._tf_tf_steps += 1\n",
    "            previous_output = target_seq[:, t:t+1, :] if use_teacher_forcing else predicted_output.detach()\n",
    "        else:\n",
    "            previous_output = predicted_output.detach()\n",
    "\n",
    "    return torch.cat(predictions, dim=1)        #[batch, output_seq_len, output_size]\n",
    "\"\"\"\n",
    "#model initialisation\n",
    "input_size  = 12\n",
    "hidden_size = 32\n",
    "output_size = 2\n",
    "epochs      = 300\n",
    "learning_rate = 0.0001\n",
    "batch_size    = 128\n",
    "num_layers    = 1        # ≥2 so encoder dropout can be active\n",
    "dropout_p     = 0.00\n",
    "weight_decay  = 0.5e-4\n",
    "\n",
    "#teacher forcing\n",
    "tf_start           = 0.7\n",
    "tf_end             = 0.1\n",
    "tf_warmup_epochs   = 0\n",
    "tf_anneal_epochs   = 80\n",
    "\n",
    "def tf_ratio_at(epoch: int) -> float:\n",
    "    if epoch < tf_warmup_epochs:\n",
    "        return tf_start\n",
    "    e = epoch - tf_warmup_epochs\n",
    "    if e >= tf_anneal_epochs:\n",
    "        return tf_end\n",
    "    frac = 1.0 - (e / tf_anneal_epochs)\n",
    "    return tf_end + (tf_start - tf_end) * frac\n",
    "\n",
    "model = EncoderDecoderAR(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    input_seq_len=input_seq_len,\n",
    "    output_seq_len=output_seq_len,\n",
    "    num_layers=num_layers,\n",
    "    dropout_p=dropout_p,\n",
    "    tf_ratio=tf_start\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=20, cooldown=0, min_lr=1e-6\n",
    ")\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "#early stopping\n",
    "patience = 150\n",
    "min_delta = 1e-5\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "#combine into dataloaders\n",
    "pin_memory = (device.type == \"cuda\") \n",
    "\n",
    "train_inputs_list, train_targets_list = [], []\n",
    "val_inputs_list,   val_targets_list   = [], []\n",
    "\n",
    "for (x_train_seq, x_val_seq, _, y_train_seq, y_val_seq, _) in datasets_seq2seq:\n",
    "    #collect training windows\n",
    "    train_inputs_list.append(x_train_seq)\n",
    "    train_targets_list.append(y_train_seq)\n",
    "\n",
    "    #collect validation windows (may be empty across datasets)\n",
    "    val_inputs_list.append(x_val_seq)\n",
    "    val_targets_list.append(y_val_seq)\n",
    "\n",
    "#ensure there are at least some training windows\n",
    "if not train_inputs_list:\n",
    "    raise RuntimeError(\"no training windows available. check windowing/splits.\")\n",
    "\n",
    "train_inputs_all = torch.cat(train_inputs_list, dim=0)\n",
    "train_targets_all = torch.cat(train_targets_list, dim=0)\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs_all, train_targets_all)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "val_loaders = []\n",
    "if val_inputs_list:\n",
    "    val_inputs_all = torch.cat(val_inputs_list, dim=0)\n",
    "    val_targets_all = torch.cat(val_targets_list, dim=0)\n",
    "\n",
    "    if val_inputs_all.size(0) > 0:\n",
    "        val_dataset = TensorDataset(val_inputs_all, val_targets_all)\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "        val_loaders = [val_loader]\n",
    "    else:\n",
    "        print(\"note: no validation windows produced; training will run without validation.\")\n",
    "\n",
    "\n",
    "#tracking records\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "best_epoch = None\n",
    "lr_history = []\n",
    "\n",
    "#TRAINING LOOP\n",
    "for epoch in range(epochs):\n",
    "    #update teacher forcing ratio for this epoch\n",
    "    model.tf_ratio = tf_ratio_at(epoch)\n",
    "\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        batch_inputs = batch_inputs.to(device, non_blocking=True)\n",
    "        batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #teacher forcing during training by passing targets\n",
    "        predictions = model(batch_inputs, batch_targets)\n",
    "        loss = criterion(predictions, batch_targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * batch_inputs.size(0)\n",
    "        total_train_samples += batch_inputs.size(0)\n",
    "\n",
    "    #average training loss\n",
    "    avg_train_loss = total_train_loss / max(1, total_train_samples)\n",
    "\n",
    "    #validation (no teacher forcing)\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for val_loader in val_loaders:\n",
    "            for batch_inputs, batch_targets in val_loader:\n",
    "                batch_inputs = batch_inputs.to(device, non_blocking=True)\n",
    "                batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "                val_preds = model(batch_inputs)  # tgt=None → autoregressive decoding only\n",
    "                val_loss = criterion(val_preds, batch_targets)\n",
    "\n",
    "                total_val_loss += val_loss.item() * batch_inputs.size(0)\n",
    "                total_val_samples += batch_inputs.size(0)\n",
    "\n",
    "    avg_val_loss = (total_val_loss / max(1, total_val_samples)) if len(val_loaders) > 0 else float('nan')\n",
    "\n",
    "    #step scheduler (prefer validation metric when available)\n",
    "    if len(val_loaders) > 0 and total_val_samples > 0:\n",
    "        scheduler.step(avg_val_loss)\n",
    "    else:\n",
    "        scheduler.step(avg_train_loss)\n",
    "\n",
    "    #record epoch metrics\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    val_loss_history.append(float(avg_val_loss) if len(val_loaders) > 0 else float('nan'))\n",
    "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    #early stopping\n",
    "    improved = (avg_val_loss + min_delta < best_val_loss) if len(val_loaders) > 0 else False\n",
    "    if improved:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = model.state_dict()\n",
    "        best_epoch = epoch\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    #loss logging\n",
    "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "        if len(val_loaders) > 0:\n",
    "            print(f\"epoch {epoch+1}/{epochs} - train loss: {avg_train_loss:.6f} - val loss: {avg_val_loss:.6f}\")\n",
    "        else:\n",
    "            print(f\"epoch {epoch+1}/{epochs} - train loss: {avg_train_loss:.6f} - (no val set)\")\n",
    "\n",
    "    #display early stopping event\n",
    "    if len(val_loaders) > 0 and epochs_no_improve >= patience:\n",
    "        print(f\"early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "#restore best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"restored best model with val loss: {best_val_loss:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "#PLOTS\n",
    "epochs_ran = len(train_loss_history)\n",
    "epoch_axis = list(range(1, epochs_ran + 1))\n",
    "\n",
    "#plot training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_axis, train_loss_history, label='train loss')\n",
    "plt.plot(epoch_axis, val_loss_history, label='validation loss')\n",
    "\n",
    "#mark best epoch with a star if available\n",
    "if best_epoch is not None and 0 <= best_epoch < epochs_ran:\n",
    "    plt.scatter(\n",
    "        best_epoch + 1,\n",
    "        val_loss_history[best_epoch],\n",
    "        marker='*',\n",
    "        s=200,\n",
    "        label='best (early-stop restore)',\n",
    "    )\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#plot learning rate over epochs\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epoch_axis, lr_history, label='learning rate')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('learning rate')\n",
    "plt.title('learning rate over epochs')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b291509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step-wise MAPE (t+1 ... t+l_out)\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def ordinal_name(k: int) -> str:\n",
    "    #1->\"1st\", 2->\"2nd\", 3->\"3rd\", else \"kth\"\n",
    "    return f\"{k}{'st' if k % 10 == 1 and k % 100 != 11 else 'nd' if k % 10 == 2 and k % 100 != 12 else 'rd' if k % 10 == 3 and k % 100 != 13 else 'th'}\"\n",
    "\n",
    "all_true_steps = [[] for _ in range(output_seq_len)]\n",
    "all_pred_steps = [[] for _ in range(output_seq_len)]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x_train_seq, x_val_seq, x_test_seq, y_train_seq, y_val_seq, y_test_seq in datasets_seq2seq:\n",
    "    test_inputs, test_targets = x_test_seq, y_test_seq\n",
    "    if len(test_inputs) == 0:\n",
    "        continue\n",
    "\n",
    "    #batched inference\n",
    "    pred_batches, true_batches = [], []\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(test_inputs, test_targets),\n",
    "        batch_size=512,\n",
    "        shuffle=False,\n",
    "        pin_memory=(device.type == \"cuda\"),\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in test_loader:\n",
    "            batch_preds = model(batch_inputs.to(device, non_blocking=True)).cpu()  #[b, l_out, 2]\n",
    "            pred_batches.append(batch_preds)\n",
    "            true_batches.append(batch_targets)\n",
    "\n",
    "    y_pred_seq = torch.cat(pred_batches, dim=0)  #[n, l_out, 2]\n",
    "    y_true_seq = torch.cat(true_batches, dim=0)  #[n, l_out, 2]\n",
    "\n",
    "    #accumulate each step across datasets\n",
    "    for t in range(output_seq_len):\n",
    "        y_pred_step = y_pred_seq[:, t, :].numpy()  #[n, 2]\n",
    "        y_true_step = y_true_seq[:, t, :].numpy()  #[n, 2]\n",
    "\n",
    "        #inverse scale using the one global scaler\n",
    "        y_pred_unscaled = Y_scaler_global.inverse_transform(y_pred_step)\n",
    "        y_true_unscaled = Y_scaler_global.inverse_transform(y_true_step)\n",
    "\n",
    "        all_pred_steps[t].append(y_pred_unscaled)\n",
    "        all_true_steps[t].append(y_true_unscaled)\n",
    "\n",
    "#overall MAPE per step across all datasets\n",
    "for t in range(output_seq_len):\n",
    "    if not all_true_steps[t]:\n",
    "        continue \n",
    "\n",
    "    y_true = np.vstack(all_true_steps[t])  #[total_n, 2]\n",
    "    y_pred = np.vstack(all_pred_steps[t])  # total_n, 2]\n",
    "\n",
    "    #guard against zeros in denominators for MAPE\n",
    "    eps = 1e-12\n",
    "    mask_y1 = np.abs(y_true[:, 0]) > eps\n",
    "    mask_y2 = np.abs(y_true[:, 1]) > eps\n",
    "\n",
    "    mape_y1 = mean_absolute_percentage_error(y_true[mask_y1, 0], y_pred[mask_y1, 0])\n",
    "    mape_y2 = mean_absolute_percentage_error(y_true[mask_y2, 1], y_pred[mask_y2, 1])\n",
    "    overall_mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "    ord_name = ordinal_name(t + 1)\n",
    "    print(f\"\\n=== overall {ord_name} mape across all datasets ===\")\n",
    "    print(f\"overall y1 mape: {mape_y1 * 100:.2f}%\")\n",
    "    print(f\"overall y2 mape: {mape_y2 * 100:.2f}%\")\n",
    "    print(f\"overall total mape: {overall_mape * 100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
